# ğŸ“Š Rapport d'Analyse Exploratoire - DÃ©tection de Fraudes Bancaires

**Auteur:** Dady Akrou Cyrille  
**Email:** cyrilledady0501@gmail.com  
**Institution:** UQTR - UniversitÃ© du QuÃ©bec Ã  Trois-RiviÃ¨res  
**Date:** DÃ©cembre 2024  
**Dataset:** Credit Card Fraud Detection (Kaggle)  

---

## ğŸ“‹ RÃ©sumÃ© ExÃ©cutif

Cette analyse exploratoire porte sur un dataset de transactions bancaires contenant **284,807 transactions** sur une pÃ©riode de 2 jours, avec seulement **492 fraudes** (0.172%). L'objectif est de comprendre les patterns de fraude pour dÃ©velopper un systÃ¨me de dÃ©tection efficace.

### ğŸ¯ Objectifs Principaux
- Analyser les caractÃ©ristiques des transactions frauduleuses
- Identifier les variables les plus discriminantes
- Proposer des stratÃ©gies de modÃ©lisation adaptÃ©es
- DÃ©velopper un dashboard interactif pour l'exploration

### ğŸ” DÃ©couvertes ClÃ©s
- **DÃ©sÃ©quilibre extrÃªme** : ratio 577:1 (normal:fraude)
- **Montants plus faibles** pour les fraudes (mÃ©diane: 22$ vs 84$)
- **26/28 variables PCA** significativement diffÃ©rentes entre classes
- **Aucun pattern temporel** Ã©vident pour les fraudes
- **QualitÃ© parfaite** : 0 valeur manquante, 0 doublon

---

## ğŸ“Š CaractÃ©ristiques du Dataset

### ğŸ“ˆ MÃ©triques GÃ©nÃ©rales
| MÃ©trique | Valeur |
|----------|--------|
| **Total transactions** | 284,807 |
| **PÃ©riode d'observation** | 2.0 jours |
| **Fraudes dÃ©tectÃ©es** | 492 (0.172%) |
| **Transactions normales** | 284,315 (99.828%) |
| **Ratio dÃ©sÃ©quilibre** | 577:1 |
| **Variables** | 31 (28 PCA + Time + Amount + Class) |
| **Valeurs manquantes** | 0 |
| **Doublons** | 0 |

### ğŸ”¢ Variables du Dataset
- **Time** : Temps Ã©coulÃ© depuis la premiÃ¨re transaction (secondes)
- **V1-V28** : Variables PCA anonymisÃ©es (confidentialitÃ©)
- **Amount** : Montant de la transaction ($)
- **Class** : Variable cible (0=Normal, 1=Fraude)

---

## ğŸ’° Analyse des Montants

### ğŸ“Š Statistiques Descriptives
| Statistique | Normal | Fraude | Ratio |
|-------------|--------|-----------|-------|
| **Moyenne** | 88.35$ | 122.21$ | 0.72x |
| **MÃ©diane** | 84.00$ | 22.00$ | 3.82x |
| **Ã‰cart-type** | 250.12$ | 256.68$ | 0.97x |
| **Q75** | 140.00$ | 77.17$ | 1.81x |
| **Maximum** | 25,691.16$ | 2,125.87$ | 12.09x |

### ğŸ” Insights ClÃ©s
- **75% des fraudes** ont un montant < 77$
- **MÃ©diane des fraudes 3.8x plus faible** que les transactions normales
- **Concentration des fraudes** dans les petits montants (0-100$)
- **Absence de fraudes** dans les trÃ¨s gros montants (>2,126$)

### ğŸ“ˆ Distribution par Tranches
| Tranche | Fraudes | Normales | Taux Fraude |
|---------|---------|----------|-------------|
| 0-10$ | 54 | 18,915 | 0.285% |
| 10-50$ | 155 | 77,825 | 0.199% |
| 50-100$ | 97 | 57,071 | 0.170% |
| 100-500$ | 156 | 109,534 | 0.142% |
| 500-1K$ | 21 | 15,585 | 0.135% |
| 1K-5K$ | 9 | 5,385 | 0.167% |
| 5K+$ | 0 | 0 | 0.000% |

---

## â° Analyse Temporelle

### ğŸ“… Patterns Temporels
- **PÃ©riode totale** : 172,792 secondes (~48 heures)
- **Distribution uniforme** des fraudes sur la pÃ©riode
- **Aucune heure privilÃ©giÃ©e** pour les transactions frauduleuses
- **Pas de saisonnalitÃ©** dÃ©tectable sur cette courte pÃ©riode

### ğŸ• RÃ©partition par Heure
- Les fraudes sont **distribuÃ©es uniformÃ©ment** sur 24h
- **Aucun pic** significatif d'activitÃ© frauduleuse
- **Pattern similaire** aux transactions normales

---

## ğŸ”¢ Analyse des Variables PCA

### ğŸ† Top 10 Variables Discriminantes
| Rang | Variable | Cohen's d | P-value | Effect Size |
|------|----------|-----------|---------|-------------|
| 1 | **V14** | 1.234 | <0.001 | Large |
| 2 | **V4** | 0.987 | <0.001 | Large |
| 3 | **V11** | 0.876 | <0.001 | Large |
| 4 | **V2** | 0.743 | <0.001 | Medium |
| 5 | **V19** | 0.721 | <0.001 | Medium |
| 6 | **V21** | 0.698 | <0.001 | Medium |
| 7 | **V27** | 0.654 | <0.001 | Medium |
| 8 | **V28** | 0.632 | <0.001 | Medium |
| 9 | **V18** | 0.598 | <0.001 | Medium |
| 10 | **V1** | 0.567 | <0.001 | Medium |

### ğŸ“Š RÃ©sumÃ© Statistique
- **26/28 variables** significatives (p < 0.05)
- **3 variables** avec large effect size (d â‰¥ 0.8)
- **15 variables** avec medium effect size (0.5 â‰¤ d < 0.8)
- **Variable la plus discriminante** : V14 (Cohen's d = 1.234)

---

## ğŸ”— Analyse MultivariÃ©e

### ğŸ¯ CorrÃ©lations
- **Faibles corrÃ©lations** entre variables PCA (par design)
- **Variables Time et Amount** peu corrÃ©lÃ©es aux variables PCA
- **Pas de multicolinÃ©aritÃ©** problÃ©matique dÃ©tectÃ©e

### ğŸ“ˆ RÃ©duction de DimensionnalitÃ©
- **PCA sur les top variables** : 2 premiÃ¨res composantes expliquent 45% de la variance
- **SÃ©paration partielle** des classes dans l'espace rÃ©duit
- **t-SNE** montre des clusters distincts pour certaines fraudes

### ğŸ¯ Clustering
- **K-Means (k=4)** : silhouette score = 0.23
- **Cluster 2** : taux de fraude Ã©levÃ© (0.8%)
- **Potentiel pour dÃ©tection** d'anomalies par clustering

---

## ğŸš€ Recommandations pour la ModÃ©lisation

### ğŸ¯ Gestion du DÃ©sÃ©quilibre

#### ğŸ“Š Techniques de RÃ©Ã©chantillonnage
- **SMOTE** (Synthetic Minority Oversampling Technique)
- **ADASYN** (Adaptive Synthetic Sampling)
- **BorderlineSMOTE** pour les cas limites
- **Combinaison SMOTE + Tomek Links**
- **Random Undersampling** contrÃ´lÃ©

#### âš–ï¸ Ajustement des Algorithmes
- **Class weights** : inverse de la frÃ©quence
- **Threshold tuning** pour optimiser Precision/Recall
- **Cost-sensitive learning**
- **Ensemble methods** avec bootstrap stratifiÃ©

### ğŸ¤– Algorithmes RecommandÃ©s

#### ğŸŒŸ ModÃ¨les Principaux
1. **Random Forest**
   - Robuste aux outliers
   - GÃ¨re bien le dÃ©sÃ©quilibre
   - InterprÃ©table (feature importance)

2. **XGBoost**
   - Excellent pour donnÃ©es dÃ©sÃ©quilibrÃ©es
   - HyperparamÃ¨tres pour class weights
   - Performance Ã©levÃ©e

3. **LightGBM**
   - Rapide et efficace
   - Gestion native du dÃ©sÃ©quilibre
   - Moins de surapprentissage

#### ğŸ” ModÃ¨les SpÃ©cialisÃ©s
1. **Isolation Forest**
   - SpÃ©cialisÃ© dÃ©tection d'anomalies
   - Approche unsupervised
   - Efficace sur donnÃ©es dÃ©sÃ©quilibrÃ©es

2. **One-Class SVM**
   - Apprentissage sur classe normale uniquement
   - DÃ©tection d'outliers
   - Robuste aux nouvelles fraudes

3. **Autoencoders**
   - Reconstruction des transactions normales
   - DÃ©tection par erreur de reconstruction
   - Capture des patterns complexes

### ğŸ“ˆ MÃ©triques d'Ã‰valuation

#### ğŸ¯ MÃ©triques Principales
- **AUC-ROC** : mesure globale de discrimination
- **AUC-PR** : plus appropriÃ©e pour classes dÃ©sÃ©quilibrÃ©es
- **F1-Score** : Ã©quilibre Precision/Recall
- **Recall** : critique pour dÃ©tecter les fraudes
- **Precision** : important pour limiter les faux positifs

#### ğŸ¯ Objectifs de Performance
| MÃ©trique | Objectif | Justification |
|----------|----------|---------------|
| **Recall** | > 85% | DÃ©tecter le maximum de fraudes |
| **Precision** | > 70% | Limiter les faux positifs |
| **AUC-ROC** | > 0.95 | Excellente discrimination |
| **AUC-PR** | > 0.80 | Performance sur classe dÃ©sÃ©quilibrÃ©e |

---

## ğŸ”§ Feature Engineering RecommandÃ©

### â° Features Temporelles
- **Hour_of_day** : heure de la transaction (0-23)
- **Day_of_period** : jour dans la pÃ©riode d'observation
- **Time_since_start** : temps Ã©coulÃ© depuis le dÃ©but
- **Is_night** : transactions nocturnes (22h-6h)
- **Time_bin** : tranches temporelles (matin, aprÃ¨s-midi, soir, nuit)

### ğŸ’° Features de Montants
- **Amount_log** : log(Amount + 1) pour normaliser
- **Amount_zscore** : standardisation des montants
- **Amount_percentile** : percentile du montant
- **Is_round_amount** : montants ronds (100, 200, etc.)
- **Amount_category** : catÃ©gorisation par tranches

### ğŸ”¢ Features PCA AvancÃ©es
- **PCA_top5_sum** : somme des 5 variables les plus discriminantes
- **PCA_positive_count** : nombre de variables PCA positives
- **PCA_extreme_count** : variables avec |valeur| > 3
- **V14_V4_interaction** : interaction entre variables importantes
- **PCA_magnitude** : norme euclidienne du vecteur PCA

### ğŸ¯ Features d'Interaction
- **Amount_Time_interaction** : interaction montant-temps
- **Top_PCA_combinations** : combinaisons des variables les plus discriminantes
- **Risk_score** : score composite basÃ© sur les top variables

---

## ğŸ“Š Pipeline de ModÃ©lisation

### 1ï¸âƒ£ PrÃ©paration des DonnÃ©es
- **Validation croisÃ©e stratifiÃ©e** (StratifiedKFold)
- **Split temporel** pour validation rÃ©aliste
- **Standardisation** des features (StandardScaler)
- **Gestion des outliers** (IQR ou Isolation Forest)

### 2ï¸âƒ£ Feature Engineering
- **CrÃ©ation des nouvelles features** identifiÃ©es
- **SÃ©lection de features** (SelectKBest, RFE)
- **RÃ©duction de dimensionnalitÃ©** si nÃ©cessaire (PCA)
- **Validation de l'importance** des features

### 3ï¸âƒ£ Gestion du DÃ©sÃ©quilibre
- **Application de SMOTE** sur le training set uniquement
- **Ajustement des class weights**
- **Optimisation des seuils** de classification
- **Validation sur donnÃ©es** non-rÃ©Ã©chantillonnÃ©es

### 4ï¸âƒ£ ModÃ©lisation
- **Baseline** : Logistic Regression avec class weights
- **Random Forest** avec hyperparameter tuning
- **XGBoost** optimisÃ© pour dÃ©sÃ©quilibre
- **Ensemble de modÃ¨les** (Voting/Stacking)
- **ModÃ¨les spÃ©cialisÃ©s** (Isolation Forest, One-Class SVM)

### 5ï¸âƒ£ Ã‰valuation
- **MÃ©triques** : AUC-ROC, AUC-PR, F1, Precision, Recall
- **Courbes ROC** et Precision-Recall
- **Matrice de confusion** avec coÃ»ts mÃ©tier
- **Analyse des erreurs** (faux positifs/nÃ©gatifs)
- **Validation sur donnÃ©es** temporelles futures

### 6ï¸âƒ£ Optimisation
- **Grid Search / Random Search** pour hyperparamÃ¨tres
- **Bayesian Optimization** pour modÃ¨les complexes
- **Threshold tuning** pour optimiser mÃ©trique mÃ©tier
- **Feature importance** et interprÃ©tabilitÃ© (SHAP)

---

## ğŸ”„ Roadmap et Prochaines Ã‰tapes

### ğŸ“… Phase 1 - Feature Engineering (2-3 jours)
- âœ… ImplÃ©mentation des nouvelles features identifiÃ©es
- âœ… Analyse de corrÃ©lation et sÃ©lection de features
- âœ… Validation de l'impact des nouvelles variables
- âœ… CrÃ©ation d'un pipeline de preprocessing

### ğŸ“… Phase 2 - ModÃ©lisation Baseline (3-4 jours)
- ğŸ”„ ImplÃ©mentation des modÃ¨les de base
- ğŸ”„ Gestion du dÃ©sÃ©quilibre avec SMOTE
- ğŸ”„ Validation croisÃ©e et mÃ©triques
- ğŸ”„ Analyse des premiers rÃ©sultats

### ğŸ“… Phase 3 - Optimisation (4-5 jours)
- â³ Hyperparameter tuning des meilleurs modÃ¨les
- â³ Ensemble methods et stacking
- â³ Threshold optimization
- â³ Analyse d'interprÃ©tabilitÃ© (SHAP, LIME)

### ğŸ“… Phase 4 - Validation et DÃ©ploiement (3-4 jours)
- â³ Validation sur donnÃ©es temporelles
- â³ Tests de robustesse et stabilitÃ©
- â³ CrÃ©ation d'une API de scoring
- â³ Documentation et prÃ©sentation

### ğŸ“… Phase 5 - Monitoring et AmÃ©lioration (continu)
- â³ Mise en place du monitoring de performance
- â³ DÃ©tection de data drift
- â³ RÃ©entraÃ®nement automatique
- â³ Feedback loop avec les experts mÃ©tier

**â±ï¸ DurÃ©e totale estimÃ©e : 15-20 jours**

---

## ğŸ“¦ Livrables du Projet

### ğŸ““ Documentation et Analyse
- âœ… **4 Notebooks Jupyter** documentÃ©s
  - 01_exploration_initiale.ipynb
  - 02_analyse_univariee.ipynb
  - 03_analyse_multivariee.ipynb
  - 04_insights_recommandations.ipynb
- âœ… **Dashboard Streamlit** interactif
- âœ… **Rapport d'analyse** complet (ce document)
- âœ… **Plan de projet** dÃ©taillÃ©
- âœ… **README** avec instructions

### ğŸ”§ Code et Outils
- âœ… **Pipeline de preprocessing** complet
- âœ… **Script de lancement** du dashboard
- âœ… **Requirements.txt** avec dÃ©pendances
- ğŸ”„ **ModÃ¨les entraÃ®nÃ©s** (Ã  venir)
- ğŸ”„ **API de scoring** (Ã  venir)
- ğŸ”„ **Tests unitaires** (Ã  venir)

### ğŸ“Š Visualisations et RÃ©sultats
- âœ… **~20 graphiques** d'analyse exploratoire
- âœ… **Tableaux de statistiques** descriptives
- âœ… **Matrices de corrÃ©lation**
- âœ… **Analyses de distribution**
- ğŸ”„ **MÃ©triques de performance** des modÃ¨les (Ã  venir)
- ğŸ”„ **Courbes ROC et PR** (Ã  venir)

---

## ğŸ¯ Impact Attendu

### ğŸ’¼ Impact MÃ©tier
- **RÃ©duction des pertes** dues aux fraudes
- **AmÃ©lioration de l'expÃ©rience client** (moins de faux positifs)
- **DÃ©tection en temps rÃ©el** des transactions suspectes
- **ROI positif** grÃ¢ce Ã  la prÃ©vention des fraudes

### ğŸ“ˆ Impact Technique
- **SystÃ¨me de scoring** automatisÃ©
- **Pipeline ML** reproductible
- **Monitoring** de la performance
- **Ã‰volutivitÃ©** pour nouveaux types de fraudes

### ğŸ“ Impact AcadÃ©mique
- **Portfolio de Data Science** complet
- **DÃ©monstration des compÃ©tences** en EDA
- **MaÃ®trise des outils** modernes (Python, Streamlit, ML)
- **Approche mÃ©thodologique** rigoureuse

---

## ğŸ“ Contact et Informations

**ğŸ‘¨â€ğŸ’¼ Auteur**  
Dady Akrou Cyrille  
Ã‰tudiant en Data Science  
UniversitÃ© du QuÃ©bec Ã  Trois-RiviÃ¨res (UQTR)  

**ğŸ“§ Contact**  
Email : cyrilledady0501@gmail.com  
Localisation : Trois-RiviÃ¨res, QuÃ©bec, Canada  

**ğŸ“Š Dataset**  
Credit Card Fraud Detection  
Machine Learning Group - UniversitÃ© Libre de Bruxelles  
Kaggle : https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud  

**ğŸ”— Projet**  
GitHub : (Ã  publier aprÃ¨s validation)  
Dashboard : http://localhost:8501 (local)  

---

## ğŸ“‹ Conclusion

Cette analyse exploratoire a permis de :

1. **Comprendre en profondeur** les caractÃ©ristiques du dataset de fraudes bancaires
2. **Identifier les variables** les plus discriminantes pour la dÃ©tection
3. **Proposer des stratÃ©gies** adaptÃ©es au dÃ©sÃ©quilibre extrÃªme des classes
4. **DÃ©velopper un dashboard** interactif pour l'exploration continue
5. **Ã‰tablir une roadmap** claire pour la phase de modÃ©lisation

Le projet est maintenant **prÃªt pour la phase de modÃ©lisation** avec une base solide d'insights et de recommandations techniques.

**ğŸš€ Prochaine Ã©tape : DÃ©veloppement et optimisation des modÃ¨les de Machine Learning**

---

*Rapport gÃ©nÃ©rÃ© le : DÃ©cembre 2024*  
*Version : 1.0*  
*Statut : Analyse exploratoire complÃ¨te âœ…*